{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = \".env\"\n",
    "load_dotenv(dotenv_path=env_path,override=True)\n",
    "api_type = \"azure\"\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = '2023-07-01-preview'\n",
    "deployment_name = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the temperature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n",
      "Pizza\n"
     ]
    }
   ],
   "source": [
    "azure_llm = AzureChatOpenAI(\n",
    "            deployment_name=deployment_name,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            api_version=\"2023-07-01-preview\",\n",
    "            azure_endpoint =endpoint,\n",
    "            api_key=api_key,\n",
    "\n",
    "        )\n",
    "promt = \"\"\"What would be a programmers favorite Food? give me the single food name only.\"\"\"\n",
    "messages =[{\"role\":\"user\",\"content\":promt}]\n",
    "\n",
    "for x in range(10):\n",
    "    response= azure_llm.invoke(messages)\n",
    "    print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "env_path = \".env\"\n",
    "load_dotenv(dotenv_path=env_path,override=True)\n",
    "api_type = \"azure\"\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = '2023-07-01-preview'\n",
    "deployment_name = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "azure_llm = AzureChatOpenAI(\n",
    "            deployment_name=deployment_name,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            api_version=\"2023-07-01-preview\",\n",
    "            azure_endpoint =endpoint,\n",
    "            api_key=api_key,\n",
    "\n",
    "        )\n",
    "def get_completion(prompt, model=azure_llm):\n",
    "    messages =[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response=model.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pizza'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"What would be a programmers favorite Food? give me the single food name only.\"\"\"\n",
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.) Be specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 3 cizgiden olusan 2 satir arasindaki text i bir satira indirecek sekilde özetle.\n",
    "- model e ne yapmamasi gerektigini söylemek yerine ne yapmasi gerektigini söylemek daha iyi sonuc verir: bir cümleden fazla yazma demek yerine 1 cümle yaz demek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering in machine learning, specifically in Natural Language Processing, involves designing prompts to guide transformer-based models like GPT-3 to provide the desired output, and the quality of the prompt significantly affects the model's performance.\n"
     ]
    }
   ],
   "source": [
    "sampletext = \"Prompt engineering is a process in machine learning, specifically in Natural Language Processing (NLP), where prompts are designed to guide the model to provide the desired output. This technique is particularly used in transformer-based models like GPT-3. The quality of the prompt can significantly affect the model's performance. It involves crafting questions or statements in a way that helps the model understand the context and give relevant responses. It can be considered as a form of 'soft coding' to instruct an AI model.\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text between two lines of triple dashes into a single sentence.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "⚠️Yukarıdaki yöntem Prompt Enjeksiyon u da önler!  Sınırlayıcı stratejinizi bilmedikleri sürece."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.) Self-check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- belirtilen göreve uygun bir input gelmediginde \"No Text Provided\" gibi farkli bir output vermeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The equation 1+1*2+3? is being asked for its result.\n"
     ]
    }
   ],
   "source": [
    "sampletext = \"1+1*2+3? equals what?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text between two lines of triple dashes into a single sentence.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Text Provided\n"
     ]
    }
   ],
   "source": [
    "sampletext = \"1+1*2+3? equals what?\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Summarize the text between two lines of triple dashes into a single sentence. Say \"No Text Provided\" if there is no text between the triple dashes.\n",
    "---\n",
    "{sampletext}\n",
    "---\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.) Few Shot Prompting\n",
    "References:\n",
    "- https://arxiv.org/pdf/2302.13971.pdf\n",
    "- https://arxiv.org/abs/2001.08361\n",
    "- https://arxiv.org/abs/2005.14165\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a>: To maximize your credit card rewards and earn the most,\n",
      "Use your card for everyday purchases, without any cost.\n",
      "Look for cards with bonus categories and sign-up bonuses too,\n",
      "And always pay off your balance on time, that's key to do.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Answer questions in a consistent style\n",
    "\n",
    "<q>: How can I learn to be a good programmer?\n",
    "<a>: In the realm of codes, where logic dances and sways,\n",
    "A quest to be a good programmer, you wish to pave your way.\n",
    "Fear not, for I shall guide you, in an enchanting lyrical play.\n",
    "\n",
    "Dive deep into the ocean of languages, where C++, Java, and Python lay,\n",
    "Choose your vessel wisely, let passion lead your way.\n",
    "\n",
    "<q>: How do I maximize my credit card rewards?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.) Time to think/ Chain-of-Thought (CoT) Prompting\n",
    "- adim adim cözüme gitmesini sagla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1+1+(2*2^2(2+3+3*5))\n",
      "= 1+1+(2*2^2(2+3+15))\n",
      "= 1+1+(2*2^2(20))\n",
      "= 1+1+(2*2*20)\n",
      "= 1+1+(2*40)\n",
      "= 1+1+80\n",
      "= 82\n"
     ]
    }
   ],
   "source": [
    "# bu hali ile komplex soru larda yanlis cevap verebilir. Burada asama asama sonuca gitmesi saglanmali\n",
    "prompt = f\"\"\"\n",
    "1+1+(2*2^2(2+3+3*5))=?\n",
    "\"\"\"\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Calculate the section between parantheses\n",
      "2*2^2(2+3+3*5) = 2*2^2(2+3+15) = 2*2^2(20) = 2*4*20 = 160\n",
      "\n",
      "2. Replace the paranteses with the result\n",
      "1+1+160\n",
      "\n",
      "3. Calculate the result\n",
      "1+1+160 = 162\n"
     ]
    }
   ],
   "source": [
    "calculation = f\"\"\"\n",
    "1+1+(2*2^2(2+3+3*5))=?\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Follow the steps below and provide your answer for each step\n",
    "1. Calculate the section between parantheses\n",
    "2. replace the paranteses with the result\n",
    "3. calculate the result\n",
    "\n",
    "---\n",
    "{calculation}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adimlarida modele buldurarak yaptirabiliiriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. First, calculate the value within the innermost parentheses:\n",
      "   2 * 2^2 = 2 * 4 = 8\n",
      "\n",
      "2. Now calculate the value within the next set of parentheses:\n",
      "   2 + 3 + 3 * 5 = 2 + 3 + 15 = 20\n",
      "\n",
      "3. Substitute the calculated values back into the original equation:\n",
      "   1 + 1 + (8 * 20)\n",
      "\n",
      "4. Next, calculate the value within the outermost set of parentheses:\n",
      "   8 * 20 = 160\n",
      "\n",
      "5. Substitute the calculated value back into the original equation:\n",
      "   1 + 1 + 160\n",
      "\n",
      "6. Finally, calculate the final sum:\n",
      "   1 + 1 + 160 = 162\n",
      "\n",
      "So, the final answer to the equation 1+1+(2*2^2(2+3+3*5)) is 162.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Give me the steps I need to follow to calculate the following?\n",
    "1+1+(2*2^2(2+3+3*5))=?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.) Hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coskun As A Service is a cloud-based platform offered by adesso that provides a range of services for businesses, including data management, analytics, and artificial intelligence. It allows companies to access and utilize advanced technologies without the need for extensive in-house resources. This platform aims to help businesses improve their operations, decision-making, and customer experiences through the use of cutting-edge technology.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "What is Coskun As A Service offering from adesso?\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genAIenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
