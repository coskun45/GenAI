{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import tiktoken\n",
    "import openai \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "env_path = \".env\"\n",
    "load_dotenv(dotenv_path=env_path,override=True)\n",
    "api_type = \"azure\"\n",
    "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "api_version = '2023-07-01-preview'\n",
    "deployment_name = os.environ.get(\"AZURE_DEPLOYMENT_NAME\")\n",
    "\n",
    "encoding = tiktoken.get_encoding('cl100k_base')\n",
    "\n",
    "azure_llm = AzureChatOpenAI(\n",
    "            deployment_name=deployment_name,\n",
    "            temperature=0,\n",
    "            max_tokens=None,\n",
    "            api_version=\"2023-07-01-preview\",\n",
    "            azure_endpoint =endpoint,\n",
    "            api_key=api_key,\n",
    "\n",
    "        )\n",
    "def get_completion(prompt, model=azure_llm):\n",
    "    messages =[{\"role\":\"user\",\"content\":prompt}]\n",
    "    response=model.invoke(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Name  | Age | Location      | Job               |\n",
      "|-------|-----|--------------|-------------------|\n",
      "| John  | 28  | New York     | Engineer          |\n",
      "| Jane  | 32  | Los Angeles  | Doctor            |\n",
      "| Harry | 24  | Chicago      | Teacher           |\n",
      "| Emma  | 30  | San Francisco| Designer          |\n",
      "| Oliver| 35  | Seattle      | Software Developer|\n"
     ]
    }
   ],
   "source": [
    "csv = f\"\"\"\n",
    "Name,Age,Location,Job\n",
    "John,28,New York,Engineer\n",
    "Jane,32,Los Angeles,Doctor\n",
    "Harry,24,Chicago,Teacher\n",
    "Emma,30,San Francisco,Designer\n",
    "Oliver,35,Seattle,Software Developer\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Convert the CSV between dashed lines into a markdown table.\n",
    "\n",
    "---\n",
    "{csv}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kişi A: Merhaba, nasılsın?\n",
      "Kişi B: Fena değilim, sadece bu soğuk havaya alışmaya çalışıyorum.\n",
      "Kişi A: Evet, mevsim o zamanı. Büyük Elma kış konusunda şakayı sevmez.\n",
      "Kişi B: Haklısın! Bu arada, 5. cadde üzerindeki yeni kahve dükkanını denedin mi?\n",
      "Kişi A: Ah, kitapçının yanındaki mi?\n",
      "Kişi B: Evet, işte o! Onların simitleri, dostum, harika.\n",
      "Kişi A: Öyleyse yarın kahvaltı için bir plan gibi görünüyor. İyi bir New York simidine asla direnemem!\n",
      "Kişi B: Seninle aynı fikirdeyim, dostum. Neyse, ben kaçmalıyım. Sonra görüşürüz?\n",
      "Kişi A: Tabii ki, sıcak kal!\n"
     ]
    }
   ],
   "source": [
    "dialog = f\"\"\"\n",
    "Person A: Hey, how you doin'?\n",
    "Person B: Not too bad, just trying to get used to this chilly weather.\n",
    "Person A: Yeah, it's that time of the year. The Big Apple doesn't play around when it comes to winter.\n",
    "Person B: You said it! By the way, have you tried the new coffee shop on 5th?\n",
    "Person A: Oh, the one next to the bookstore?\n",
    "Person B: That's the one! Their bagels, man, they’re outta this world.\n",
    "Person A: Sounds like a plan for tomorrow's breakfast then. I can never resist a good New York bagel!\n",
    "Person B: You and me both, buddy. Anyway, I gotta run. Catch you later?\n",
    "Person A: Sure thing, stay warm out there!\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Convert the dialog between dashed lines to formal Turkish.\n",
    "\n",
    "---\n",
    "{dialog}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spellcheck and Grammar Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't like to read books because it is too boring. My friend, they don't like it too. We prefer to play video games and watch movies. There is a new game that came out yesterday, I want to buy it soon.\n"
     ]
    }
   ],
   "source": [
    "dialog = f\"\"\"\n",
    "I doesnt likes to reading books becose it is to boring. My freind, they don't likes it to. We prefers to playing video games and watching moovies. Their is a new game that came's out yesterday, I wants to buy it soon.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Spellcheck the text between the dashed lines. Provide the correct spelling for any misspelled words.\n",
    "\n",
    "---\n",
    "{dialog}\n",
    "---\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openai-qna-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4ee1bbf3137c7ea9420c4fd488a55642063e5739fe2a7286130d9ba47405b69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
