{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmkarakaya/Deep-Learning-Tutorials/blob/master/Simple_Rag_with_chromaDB_Gemini_PartB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYN6tFZoaPm2"
      },
      "source": [
        "# PART B: CODE CHROMADB FOR VECTOR STORAGE & SIMILARITY SEARCH    \n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGmLFS7j8JSQ"
      },
      "source": [
        "In this notebook we will develop a Retrieval Augmented Generation (RAG) application.\n",
        "\n",
        "The Parts are\n",
        "\n",
        "* PART A: AN INTRO TO GEMINI API FOR TEXT GENERATION & CHAT\n",
        "* PART B: CODE WITH CHROMADB FOR VECTOR STORAGE & SIMILARITY SEARCH\n",
        "* PART C: CODE WITH CHROMADB FOR PERSISTENT VECTOR DB\n",
        "* PART D: A SIMPLE RAG BASED ON GEMINI & CHROMADB\n",
        "* PART E: ADVANCED TECHNIQUES FOR RAG BASED ON GEMINI & CHROMADB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1ZwDQFa5eNJ"
      },
      "source": [
        "YouTube Playlist:\n",
        "* Türkçe: Erişim Destekli Metin Üretimi : https://www.youtube.com/playlist?list=PLQflnv_s49v_nrk7iGYqw5iRAKrSZPnnV\n",
        "\n",
        "* English: Retrieval Augmented Generation (RAG) https://www.youtube.com/playlist?list=PLQflnv_s49v-EFKdOVDKB743f1iskLLw2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R91gZB4JIZO7"
      },
      "source": [
        "What is RAG?\n",
        "\n",
        "RAG stands for Retrieval-Augmented Generation. It's a technique that combines large language models (LLMs) with external knowledge sources to improve the accuracy and reliability of AI-generated text.\n",
        "\n",
        "## How Does RAG Work? Unveiling the Power of External Knowledge\n",
        "\n",
        "Before we start the core RAG process, we need to provide a foundation as follows:\n",
        "\n",
        "* **Building the Knowledge Base:** The system starts by transforming documents and information within the external knowledge base (like Wikipedia or a company database) into a special format called **vector representations**. These condense the meaning of each document into a series of **numbers**, capturing the essence of the content.\n",
        "\n",
        "* **Vector Database for Speedy Retrieval**: These vector representations are then stored in a specialized database called a vector database. This database is optimized for efficiently **searching and retrieving** information based on **semantic similarity**. Imagine it as a super-powered library catalog that **understands the meaning** of documents, **not just keywords**.\n",
        "\n",
        "Now, let's explore how RAG leverages this foundation:\n",
        "\n",
        "* **User Input**: The RAG process begins with a question or **prompt** from the user. This could be anything from \"What caused the extinction of the dinosaurs?\" to a more open-ended request like \"Write a creative story.\"\n",
        "\n",
        "* **Intelligent Retrieval**: RAG doesn't rely solely on the **LLM's internal knowledge**. It employs an information retrieval component that acts like a super-powered search engine. This component scans the vast external knowledge base – like a company's internal database for specific domains – to find information **directly relevant** to the user's input. Unlike a traditional **search engine** that relies on **keywords**, RAG leverages the power of vector representations to understand the **semantic meaning** of the user's prompt and identify the most relevant documents.\n",
        "\n",
        "* **Enriched Context Creation**: The retrieved information isn't just shown alongside the prompt. RAG cleverly **merges the user input with the relevant snippets** from the knowledge base. This creates a ***richer context*** for the LLM to understand the **user's intent** and formulate a well-informed response.\n",
        "\n",
        "* **LLM Powered Response Generation**: Finally, the **enriched context** is fed to the Large Language Model (LLM). The LLM, along with its ability to process language patterns, now has a strong **foundation of factual** information to draw upon. This empowers it to generate a response that is both comprehensive and accurate, addressing the specific needs of the user's prompt.\n",
        "\n",
        "In this part, we will learn how to Build a Vector Database for Speedy Retrieval in a Knowledge Base using ChromaDB\n",
        "\n",
        "https://www.trychroma.com/\n",
        "https://github.com/chroma-core/chroma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Niu38r_Gwqe"
      },
      "source": [
        "# CONTENT\n",
        "\n",
        "In this exciting tutorial series, we are developing a Retrieval Augmented Generation (RAG) application. If you missed the first part where we covered how to code the GEMINI API for text generation and chat, be sure to check that out.\n",
        "\n",
        "In this second part, we will code with ChromaDB for vector storage and similarity search with **multiple documents**.\n",
        "\n",
        "In this tutorial, we will learn:\n",
        "\n",
        "* How Does RAG Work? – Understand the fundamentals of Retrieval Augmented Generation.\n",
        "* Upload Single and Multiple PDF Documents to ChromaDB – Learn to handle various document types.\n",
        "* Convert PDF Content to Text Format – Extract text from PDFs efficiently.\n",
        "* Convert Text from Pages to Chunks – Organize text for better processing.\n",
        "* Tokenize the Text – Prepare your text data for machine learning.\n",
        "* Use the Sentence Transformers Library – Implement advanced text encoding techniques.\n",
        "* Understand Vector Embedding – Grasp the concept of embedding vectors.\n",
        "* Create a ChromaDB Instance for Single and Multiple Files/Documents – Set up your database for efficient storage.\n",
        "* Query and Retrieve Chunks from ChromaDB – Learn to search and retrieve relevant information.\n",
        "* Filtering Results – Refine your search results.\n",
        "* Remove Less Related/Less Similar Chunks – Improve the accuracy of your retrieval process.\n",
        "\n",
        "All the above steps will be implemented and coded in Python on Google Colab.\n",
        "\n",
        "Follow along step-by-step to master these techniques and enhance your data processing capabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPPTG2KRDT97"
      },
      "source": [
        "# Building the Knowledge Base\n",
        "\n",
        "##  Upload pdf documents\n",
        "During this tutorial, I will consider the pdf files to build the knowledge base. However, you can extend the this notebook easily  to handle the other file types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iM6oMSEFDb9H"
      },
      "outputs": [],
      "source": [
        "from tkinter import Tk\n",
        "from tkinter.filedialog import askopenfilenames\n",
        "def upload_multiple_files():\n",
        "    # Küçük tkinter penceresini gizle\n",
        "    Tk().withdraw()\n",
        "\n",
        "    # Birden fazla dosya seçmek için dosya seçici aç\n",
        "    filenames = askopenfilenames(\n",
        "        title=\"Dosyaları Seçin\",\n",
        "        filetypes=[(\"Tüm Dosyalar\", \"*.*\")]  # İsteğe bağlı olarak dosya türlerini filtreleyebilirsiniz\n",
        "    )\n",
        "\n",
        "    return filenames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "gBL3agj2FZYe",
        "outputId": "c8fbd254-928f-4e80-8d53-d91401fc4ed8"
      },
      "outputs": [],
      "source": [
        "file_names = upload_multiple_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iVbaP_n7H1Nb",
        "outputId": "da88b0b6-4d52-4614-c095-d889158afad8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'C:/Users/ecoskun/Downloads/Bir Müslümanın Yol Haritası - Akademi A. Heyeti.pdf'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file_names[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jgOITJJGcAa"
      },
      "source": [
        "## Convert PDF content to text format\n",
        "Let's see how can we do it on a single file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUjIVHIRHLvr",
        "outputId": "ae933e31-4081-4cde-9239-65d8272c1a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pypdf --quiet\n",
        "from pypdf import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jyQT7DCiGSZy"
      },
      "outputs": [],
      "source": [
        "def convert_PDF_Text(pdf_path):\n",
        "  reader = PdfReader(pdf_path)\n",
        "  pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
        "  # Filter the empty strings\n",
        "  pdf_texts = [text for text in pdf_texts if text]\n",
        "  print(\"Document: \",pdf_path,\" chunk size: \", len(pdf_texts))\n",
        "  return pdf_texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "HaNxhSGBEp8v",
        "outputId": "16d977fa-71e4-4826-e0aa-f7410adac0f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document:  C:/Users/ecoskun/Downloads/Bir Müslümanın Yol Haritası - Akademi A. Heyeti.pdf  chunk size:  839\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'1. Giriş\\n2. İman Esasları\\n3. Kâinatı Yaratan Allah (cc)\\n4. Nübüvve t (Peygamberlik Müessesesi)\\n5. İnsanlığa Lütfedilen İlâhî Kitaplar\\n6. Fizik Ötesi/Nuranî Varlıklar: Melekler\\n7. İlâhî Takdir: Kader\\n8. Ölüm Ötesi Sonsuz Hayat: Âhiret\\n9. İbadet Mükellefiyeti\\n10. Namaz\\n11. Oruç\\n12. Zekât\\n13. Hac\\n14. Helâl ve Haramlar\\n15. Temizlik\\n16. Ahlâk\\n17. Kurban'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pdf_texts = convert_PDF_Text(file_names[0])\n",
        "pdf_texts[0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJFqj-MCIWpV"
      },
      "source": [
        "The to_markdown function converts plain text to Markdown format, adding blockquote styling and converting bullet points."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FvuLQlB4IRb8"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "_3-_G2wf8OdS",
        "outputId": "c2b536e3-8139-4b4e-9f31-da510f241b89"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> 1. Giriş\n",
              "> 2. İman Esasları\n",
              "> 3. Kâinatı Yaratan Allah (cc)\n",
              "> 4. Nübüvve t (Peygamberlik Müessesesi)\n",
              "> 5. İnsanlığa Lütfedilen İlâhî Kitaplar\n",
              "> 6. Fizik Ötesi/Nuranî Varlıklar: Melekler\n",
              "> 7. İlâhî Takdir: Kader\n",
              "> 8. Ölüm Ötesi Sonsuz Hayat: Âhiret\n",
              "> 9. İbadet Mükellefiyeti\n",
              "> 10. Namaz\n",
              "> 11. Oruç\n",
              "> 12. Zekât\n",
              "> 13. Hac\n",
              "> 14. Helâl ve Haramlar\n",
              "> 15. Temizlik\n",
              "> 16. Ahlâk\n",
              "> 17. Kurban"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(pdf_texts[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BtPr8pJJB7S"
      },
      "source": [
        "Let's how many pages we have in that file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JtXr0uI0Gb3",
        "outputId": "c5718201-9d89-47d5-8824-0340458aeefb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C:/Users/ecoskun/Downloads/Bir Müslümanın Yol Haritası - Akademi A. Heyeti.pdf  has  839  pages\n"
          ]
        }
      ],
      "source": [
        "print(file_names[0],\" has \", len(pdf_texts), \" pages\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRLsnTKEEuXW"
      },
      "source": [
        "## Convert Text from Pages to Chunks\n",
        "The code below defines a **character_splitter** object using a class called **RecursiveCharacterTextSplitter**. This object is intended to ***split text into smaller chunks based on certain criteria***.\n",
        "\n",
        "This text splitter is the recommended one for generic text. It is parameterized by a list of characters. It tries to split on them in order until the chunks are small enough. The default list is [\"\\n\\n\", \"\\n\", \" \", \"\"]. **This has the effect of trying to keep all paragraphs (and then sentences, and then words) together as long as possible, as those would generically seem to be the strongest semantically related pieces of text.**\n",
        "\n",
        "* How the text is split: by list of characters.\n",
        "\n",
        "* How the chunk size is measured: by number of characters.\n",
        "\n",
        "Let's break down the parameters:\n",
        "\n",
        "* separators: This parameter defines the characters or strings that will be used as separators to split the text. In this case, the separators include \"\\n\\n\" (double newline), \"\\n\" (single newline), \". \" (period followed by a space), \" \" (space), and \"\" (empty string). These separators will be used to split the text into smaller chunks.\n",
        "\n",
        "* chunk_size: This parameter specifies the maximum size of each chunk of text after splitting. In this case, each chunk will have a maximum size of 1500 characters.\n",
        "\n",
        "* chunk_overlap: This parameter determines whether there will be any overlap between adjacent chunks. A value of 0 means no overlap. In this case, there is no overlap between chunks.\n",
        "\n",
        "Overall, this code initializes a character_splitter object that can split text into smaller chunks based on the specified separators, with a maximum size of 1500 characters per chunk and no overlap between chunks.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fT8IojKA0gxa",
        "outputId": "0138c5ed-8576-44af-ee69-24873ff2a1ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install langchain --quiet\n",
        "import langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "uSbYRprM1BMe"
      },
      "outputs": [],
      "source": [
        "def convert_Page_ChunkinChar(pdf_texts, chunk_size = 1500, chunk_overlap=0 ):\n",
        "  character_splitter = RecursiveCharacterTextSplitter(\n",
        "      separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "      chunk_size=1500,\n",
        "      chunk_overlap=0\n",
        ")\n",
        "  character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
        "  print(f\"\\nTotal number of chunks (document splited by max char = 1500): \\\n",
        "        {len(character_split_texts)}\")\n",
        "  return character_split_texts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPuE36vpKatj",
        "outputId": "b1ab4f15-8996-4eeb-c2f0-2c7bd7658323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of chunks (document splited by max char = 1500):         1361\n"
          ]
        }
      ],
      "source": [
        "text_chunksinChar = convert_Page_ChunkinChar(pdf_texts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzvDCd7EK6L2",
        "outputId": "a21970c6-15c4-4e9e-ee40-b3dd7e6f0801"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "................. NOTICE ..................\n",
            "C:/Users/ecoskun/Downloads/Bir Müslümanın Yol Haritası - Akademi A. Heyeti.pdf  has  839  pages\n",
            "C:/Users/ecoskun/Downloads/Bir Müslümanın Yol Haritası - Akademi A. Heyeti.pdf  has  1361  chunks\n",
            "chunk [0] has  540  chars\n",
            "chunk [-1] has  69  chars\n"
          ]
        }
      ],
      "source": [
        "print(\"................. NOTICE ..................\")\n",
        "print(file_names[0],\" has \", len(pdf_texts), \" pages\")\n",
        "print(file_names[0],\" has \", len(text_chunksinChar), \" chunks\")\n",
        "print(\"chunk [0] has \", len(text_chunksinChar[0]), \" chars\")\n",
        "print(\"chunk [-1] has \", len(text_chunksinChar[-1]), \" chars\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6m0xYt7TFstR"
      },
      "source": [
        "## Convert Text from Chunks to Tokens\n",
        "\n",
        "This code is designed to tokenize the text chunks produced by the previous code using the `SentenceTransformersTokenTextSplitter`. Let's break down the code and its purpose:\n",
        "\n",
        "1. `token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, model_name=\"distiluse-base-multilingual-cased-v1\", tokens_per_chunk=128)`: This line initializes a tokenizer object named `token_splitter`. It utilizes the `SentenceTransformersTokenTextSplitter` class, which tokenizes text into chunks based on a specified model. The parameters provided are:\n",
        "   - `chunk_overlap=0`: This parameter specifies that there should be no overlap between tokenized chunks.\n",
        "   - `model_name=\"distiluse-base-multilingual-cased-v1\"`: This parameter specifies the name of the pre-trained model to be used for tokenization. In this case, it's using the \"distiluse-base-multilingual-cased-v1\" model.\n",
        "\n",
        "   - `tokens_per_chunk=128`: This parameter determines the maximum number of tokens allowed per chunk after tokenization.\n",
        "\n",
        "2. `token_split_texts = []`: This line initializes an empty list to store the tokenized text chunks.\n",
        "\n",
        "3. `for text in character_split_texts:`: This line starts a loop iterating over the text chunks produced by the character splitter.\n",
        "\n",
        "4. `token_split_texts += token_splitter.split_text(text)`: Within the loop, this line tokenizes each text chunk using the `token_splitter` object and adds the resulting tokenized chunks to the `token_split_texts` list.\n",
        "\n",
        "5. `print(token_split_texts[10])`: This line prints out the 11th tokenized chunk for inspection.\n",
        "\n",
        "6. `print(f\"\\nTotal chunks: {len(token_split_texts)}\")`: This line prints out the total number of tokenized chunks produced.\n",
        "\n",
        "The reason for applying this code after the character splitting code is likely to further process the text data. Character splitting breaks down the text into smaller, more manageable chunks, and tokenization further breaks down those chunks into individual tokens, often for tasks like natural language processing (NLP) or machine learning. By applying both character splitting and tokenization, the text data becomes more structured and suitable for various NLP tasks.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP8cXqTPPz6v",
        "outputId": "119486c3-96da-4509-af86-25cbe9e2a301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install sentence-transformers --quiet\n",
        "%pip install tqdm --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aDTLGy5VH15B"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import SentenceTransformersTokenTextSplitter\n",
        "sentence_transformer_model=\"distiluse-base-multilingual-cased-v1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "t3Lc9OSD1T6P"
      },
      "outputs": [],
      "source": [
        "def convert_Chunk_Token(text_chunksinChar,sentence_transformer_model, chunk_overlap=0,tokens_per_chunk=128 ):\n",
        "  token_splitter = SentenceTransformersTokenTextSplitter(\n",
        "      chunk_overlap=chunk_overlap,\n",
        "      model_name=sentence_transformer_model,\n",
        "      tokens_per_chunk=tokens_per_chunk)\n",
        "\n",
        "  text_chunksinTokens = []\n",
        "  for text in text_chunksinChar:\n",
        "      text_chunksinTokens += token_splitter.split_text(text)\n",
        "  print(f\"\\nTotal number of chunks (document splited by 128 tokens per chunk):\\\n",
        "       {len(text_chunksinTokens)}\")\n",
        "  return text_chunksinTokens\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7eQB5iJt1HEF"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm, trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evIO-Xo3N6pK",
        "outputId": "0d23b877-c16f-4b5b-9890-c947c451f53f"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[WinError 126] The specified module could not be found. Error loading \"c:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_chunksinTokens \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_Chunk_Token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_chunksinChar\u001b[49m\u001b[43m,\u001b[49m\u001b[43msentence_transformer_model\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[16], line 2\u001b[0m, in \u001b[0;36mconvert_Chunk_Token\u001b[1;34m(text_chunksinChar, sentence_transformer_model, chunk_overlap, tokens_per_chunk)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_Chunk_Token\u001b[39m(text_chunksinChar,sentence_transformer_model, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,tokens_per_chunk\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m ):\n\u001b[1;32m----> 2\u001b[0m   token_splitter \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformersTokenTextSplitter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mchunk_overlap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunk_overlap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence_transformer_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtokens_per_chunk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokens_per_chunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m   text_chunksinTokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m text_chunksinChar:\n",
            "File \u001b[1;32mc:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\langchain_text_splitters\\sentence_transformers.py:22\u001b[0m, in \u001b[0;36mSentenceTransformersTokenTextSplitter.__init__\u001b[1;34m(self, chunk_overlap, model_name, tokens_per_chunk, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, chunk_overlap\u001b[38;5;241m=\u001b[39mchunk_overlap)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformer python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is needed in order to for SentenceTransformersTokenTextSplitter. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\__init__.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
            "File \u001b[1;32mc:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      3\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Callable, Dict, List, Literal, Optional, Tuple, Type, Union\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, nn\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optimizer\n",
            "File \u001b[1;32mc:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
            "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"c:\\Users\\ecoskun\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
          ]
        }
      ],
      "source": [
        "text_chunksinTokens = convert_Chunk_Token(text_chunksinChar,sentence_transformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "HJd1WOxBQzdj",
        "outputId": "3c5f7fc7-7a55-40f6-ebc5-9330db3e4559"
      },
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering: An International Journal (CSEIJ), Vol. 4, No. 1, February 2014\n",
              "> DOI : 10.5121/cseij.2014.410 3 27UAVROUTEPLANNING FORMAXIMUMTARGET\n",
              "> COVERAGE\n",
              "> MuratKarakaya1\n",
              "> 1Department of Computer Engineering ,Atilim University ,Ankara,Turkey\n",
              "> ABSTRACT\n",
              "> Utilization of Unmanned Aerial Vehicles (UAVs) in military and civil operations is getting popular. One of\n",
              "> the challenges in effectively tasking these expensive vehicles is planning the flight routes to monitor the\n",
              "> targets. In this work, we aim to develop an algorithm which produces routing plans for a limited number of\n",
              "> UAVs to cover maximum number of target s considering their flight range.\n",
              "> The proposed solution for this practical optimization problem is designed by modifying the Max -Min Ant\n",
              "> System (MMAS) algorithm.  To evaluate the success of the proposed method, an alternative approach,\n",
              "> based on the Neares t Neighbour (NN) heuristic, has been developed as well. The results showed the success\n",
              "> of the proposed MMAS method by increasing the number of covered targets compared to the sol ution based\n",
              "> on the NN heuristic .\n",
              "> KEYWORDS\n",
              "> Unmanned Aerial Vehicles (UAVs), r outing, target coverage, Max -Min Ant Colony Optimization\n",
              "> 1.INTRODUCTION\n",
              "> This document describes, and is written to conform to, author guidelines for the journals of\n",
              "> AIRCCseries.  It is prepared in Microsoft Word as a .doc document.  Although other mea ns of\n",
              "> preparation are acceptable, final, camera -ready versions must conform to this layout.  Microsoft"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "to_markdown(text_chunksinChar[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "id": "7-EdCBw-QQ3r",
        "outputId": "b3cf80c5-2001-4171-c2b9-2cf23c07b4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "................. NOTICE ..................\n",
            "15 UAV Route Planning For Maximum Target Coverage.pdf  has  8  pages\n",
            "15 UAV Route Planning For Maximum Target Coverage.pdf  has  14  chunks splitted by 1500 chars\n",
            "15 UAV Route Planning For Maximum Target Coverage.pdf  has  41  chunks splitted by 128 tokens\n",
            "text_chunksinChar [0] is:\n",
            " \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering: An International Journal (CSEIJ), Vol. 4, No. 1, February 2014\n",
              "> DOI : 10.5121/cseij.2014.410 3 27UAVROUTEPLANNING FORMAXIMUMTARGET\n",
              "> COVERAGE\n",
              "> MuratKarakaya1\n",
              "> 1Department of Computer Engineering ,Atilim University ,Ankara,Turkey\n",
              "> ABSTRACT\n",
              "> Utilization of Unmanned Aerial Vehicles (UAVs) in military and civil operations is getting popular. One of\n",
              "> the challenges in effectively tasking these expensive vehicles is planning the flight routes to monitor the\n",
              "> targets. In this work, we aim to develop an algorithm which produces routing plans for a limited number of\n",
              "> UAVs to cover maximum number of target s considering their flight range.\n",
              "> The proposed solution for this practical optimization problem is designed by modifying the Max -Min Ant\n",
              "> System (MMAS) algorithm.  To evaluate the success of the proposed method, an alternative approach,\n",
              "> based on the Neares t Neighbour (NN) heuristic, has been developed as well. The results showed the success\n",
              "> of the proposed MMAS method by increasing the number of covered targets compared to the sol ution based\n",
              "> on the NN heuristic .\n",
              "> KEYWORDS\n",
              "> Unmanned Aerial Vehicles (UAVs), r outing, target coverage, Max -Min Ant Colony Optimization\n",
              "> 1.INTRODUCTION\n",
              "> This document describes, and is written to conform to, author guidelines for the journals of\n",
              "> AIRCCseries.  It is prepared in Microsoft Word as a .doc document.  Although other mea ns of\n",
              "> preparation are acceptable, final, camera -ready versions must conform to this layout.  Microsoft"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text_chunksinTokens for the first 3 chunks are:\n",
            " \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 DOI : 10. 5121 / cseij. 2014. 410 3 27UAVROUTEPLANNING FORMAXIMUMTARGET COVERAGE MuratKarakaya1 1Department of Computer Engineering, Atilim University, Ankara, Turkey ABSTRACT Utilization of Unmanned Aerial Vehicles ( UAVs ) in military and civil operations is getting popular. One of the challenges in effectively tasking these expensive vehicles is planning"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "> the flight routes to monitor the targets. In this work, we aim to develop an algorithm which produces routing plans for a limited number of UAVs to cover maximum number of target s considering their flight range. The proposed solution for this practical optimization problem is designed by modifying the Max - Min Ant System ( MMAS ) algorithm. To evaluate the success of the proposed method, an alternative approach, based on the Neares t Neighbour ( NN ) heuristic, has been developed as well. The results showed the success of the proposed MMAS method by increasing the number of covered targets compared to the"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/markdown": [
              "> sol ution based on the NN heuristic. KEYWORDS Unmanned Aerial Vehicles ( UAVs ), r outing, target coverage, Max - Min Ant Colony Optimization 1. INTRODUCTION This document describes, and is written to conform to, author guidelines for the journals of AIRCCseries. It is prepared in Microsoft Word as a. doc document. Although other mea ns of preparation are acceptable, final, camera - ready versions must conform to this layout. Microsoft"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(\"................. NOTICE ..................\")\n",
        "print(file_names[0],\" has \", len(pdf_texts), \" pages\")\n",
        "print(file_names[0],\" has \", len(text_chunksinChar), \" chunks splitted by 1500 chars\")\n",
        "print(file_names[0],\" has \", len(text_chunksinTokens), \" chunks splitted by 128 tokens\")\n",
        "print(\"text_chunksinChar [0] is:\\n \")\n",
        "display(to_markdown(text_chunksinChar[0]))\n",
        "print(\"text_chunksinTokens for the first 3 chunks are:\\n \")\n",
        "display(to_markdown(text_chunksinTokens[0]))\n",
        "display(to_markdown(text_chunksinTokens[1]))\n",
        "display(to_markdown(text_chunksinTokens[2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ge5CqAm2Lxq"
      },
      "source": [
        "##Sentence Transformers Library##\n",
        "**IMPORTANT:** The `SentenceTransformersTokenTextSplitter` class depends on  the `sentence_transformers` library and uses the models supported by the `sentence_transformers` library.\n",
        "\n",
        "You can access the `sentence_transformers` library using the link: https://www.sbert.net/docs/pretrained_models.html\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Multi-Lingual Models supported by Sentence Transformers Library##\n",
        "The following models generate aligned vector spaces, i.e., similar inputs in different languages are mapped close in vector space. You do not need to specify the input language: https://www.sbert.net/docs/pretrained_models.html#multi-lingual-models\n",
        "\n",
        "###Semantic Similarity:###\n",
        "These models find semantically similar sentences within one language or across languages:\n",
        "\n",
        "**distiluse-base-multilingual-cased-v1**: Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. Supports 15 languages: Arabic, Chinese, Dutch, English, French, German, Italian, Korean, Polish, Portuguese, Russian, Spanish, **Turkish**.\n",
        "\n",
        "**distiluse-base-multilingual-cased-v2:** Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. This version supports 50+ languages, but performs a bit weaker than the v1 model.\n",
        "\n",
        "**paraphrase-multilingual-MiniLM-L12-v2:** Multilingual version of paraphrase-MiniLM-L12-v2, trained on parallel data for 50+ languages.\n",
        "\n",
        "**paraphrase-multilingual-mpnet-base-v2:** Multilingual version of paraphrase-mpnet-base-v2, trained on parallel data for 50+ languages.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sH434Fpcr2E"
      },
      "source": [
        "## Understand the Vector Embeddings\n",
        "\n",
        "Below, we import the chromadb library and its utility for **embedding functions**, then sets up an embedding function using the specified SentenceTransformer model in the above code  for creating vector representations of text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_alJcracK7Y",
        "outputId": "04b890bf-8306-46d4-da52-91a69811cf29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m559.5/559.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.0/92.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.9/59.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.0/107.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install chromadb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SpqY5o252OF9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(model_name=sentence_transformer_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gO3UGXQdWRX"
      },
      "source": [
        "Let's first see how to convert  a text which is splitted according to token size = 128 into a vector represantation by using the ***embedding_function***:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Ua4i4hkY1xcn",
        "outputId": "c1121e00-1247-4e54-cc5c-54ab60ec1505"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "text (128 token max):\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 DOI : 10. 5121 / cseij. 2014. 410 3 27UAVROUTEPLANNING FORMAXIMUMTARGET COVERAGE MuratKarakaya1 1Department of Computer Engineering, Atilim University, Ankara, Turkey ABSTRACT Utilization of Unmanned Aerial Vehicles ( UAVs ) in military and civil operations is getting popular. One of the challenges in effectively tasking these expensive vehicles is planning"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding Vector shape:  (1, 512)\n",
            "Embedding Vector dimension:  512\n",
            "Embedding Vector content (for first 5 dimension): \n",
            " [0.06848306208848953, -0.027248548343777657, 0.008307364769279957, 0.01328625064343214, -0.006611280608922243]\n"
          ]
        }
      ],
      "source": [
        "chunk=0\n",
        "print(\"text (128 token max):\\n\")\n",
        "display(to_markdown(text_chunksinTokens[chunk]))\n",
        "embedding_vector= embedding_function([text_chunksinTokens[chunk]])\n",
        "print(\"Embedding Vector shape: \",np.shape(embedding_vector))\n",
        "print(\"Embedding Vector dimension: \",len(embedding_vector[0]))\n",
        "print(\"Embedding Vector content (for first 5 dimension): \\n\",embedding_vector[0][0:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T0P7CV7gdla"
      },
      "source": [
        "# CREATE A CHROMADB INSTANCE\n",
        "Let's create a ChromaDB client for storing and retrieving vectors.\n",
        "\n",
        "1. **Importing the Client**: The code imports the `Client` class from the `chromadb` library, which will be used for interacting with a database that handles embeddings.\n",
        "\n",
        "2. **Creating an Instance of the Client**: It creates an instance of the `Client` class named `chroma_client`. This instance will be used to interact with the database.\n",
        "\n",
        "3. **Creating a Collection**: It creates a new collection named \"Papers\" in the database. The `create_collection` method takes two arguments:\n",
        "   - `\"Papers\"`: The name of the collection.\n",
        "   - `embedding_function`: A function (defined above) that generates embeddings for the items to be stored in the collection.\n",
        "\n",
        "This code sets up the necessary client and collection in a database designed to handle and store embeddings, which are typically used for tasks involving similarity search, clustering, or other vector-based queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZpdNZxrIb-F"
      },
      "source": [
        "## Create a ChromaDB client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9f-787m26dQ"
      },
      "outputs": [],
      "source": [
        "from chromadb import Client\n",
        "def create_chroma_client(collection_name, embedding_function):\n",
        "  chroma_client = Client()\n",
        "  chroma_collection = chroma_client.get_or_create_collection(collection_name, embedding_function=embedding_function)\n",
        "  return chroma_client, chroma_collection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q1nDOk4IiZ2"
      },
      "source": [
        "## Create a ChromaDB collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L5zKrIXjHUT",
        "outputId": "ce523b55-9fd8-4bba-f810-d4fbdddd4bd0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "[<chromadb.api.models.Collection.Collection object at 0x78ad614480a0>]\n"
          ]
        }
      ],
      "source": [
        "collection_name= \"Papers\"\n",
        "chroma_client, chroma_collection = create_chroma_client(collection_name, embedding_function)\n",
        "print(chroma_collection.count())\n",
        "print(chroma_client.list_collections())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2weI3NciRjK"
      },
      "source": [
        "NOTE: We provided the embedding function to the Chroma Client. Thus, it will use the embedding function automatically when we provide the text in chunks splitted according to token limit = 128!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62XBii5biq0s"
      },
      "source": [
        "## Prepare Metadata\n",
        "\n",
        "Provide some meta data for the text chuncks such as the source file name and category."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JCEbASQ1hNw4"
      },
      "outputs": [],
      "source": [
        "def add_meta_data(text_chunksinTokens, title, category, initial_id):\n",
        "  ids = [str(i+initial_id) for i in range(len(text_chunksinTokens))]\n",
        "  metadata = {\n",
        "      'document': title,\n",
        "      'category': category\n",
        "  }\n",
        "  metadatas = [ metadata for i in range(len(text_chunksinTokens))]\n",
        "  return ids, metadatas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AIsvK1KkSth",
        "outputId": "89217de6-7d6d-4df9-a059-5aa2c973e912"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['0', '1', '2', '3', '4'],\n",
              " [{'document': '15 UAV Route Planning For Maximum Target Coverage.pdf',\n",
              "   'category': 'Journal Paper'},\n",
              "  {'document': '15 UAV Route Planning For Maximum Target Coverage.pdf',\n",
              "   'category': 'Journal Paper'},\n",
              "  {'document': '15 UAV Route Planning For Maximum Target Coverage.pdf',\n",
              "   'category': 'Journal Paper'},\n",
              "  {'document': '15 UAV Route Planning For Maximum Target Coverage.pdf',\n",
              "   'category': 'Journal Paper'},\n",
              "  {'document': '15 UAV Route Planning For Maximum Target Coverage.pdf',\n",
              "   'category': 'Journal Paper'}])"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category=\"Journal Paper\"\n",
        "ids,metadatas = add_meta_data(text_chunksinTokens,file_names[0],category, 0)\n",
        "ids[:5], metadatas[:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqwZA71_It5n"
      },
      "source": [
        "## Add the document and metadata to the ChromaDB collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGvJdwJ7ggo3"
      },
      "outputs": [],
      "source": [
        "def add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection):\n",
        "  print(\"Before inserting, the size of the collection: \", chroma_collection.count())\n",
        "  chroma_collection.add(ids=ids, metadatas= metadatas, documents=text_chunksinTokens)\n",
        "  print(\"After inserting, the size of the collection: \", chroma_collection.count())\n",
        "  return chroma_collection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LzVHYGr3ii7I",
        "outputId": "4fa997a2-bee3-4597-ec39-0b2950bd3660"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before inserting, the size of the collection:  0\n",
            "After inserting, the size of the collection:  41\n"
          ]
        }
      ],
      "source": [
        "chroma_collection = add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxs_FhjQI55-"
      },
      "source": [
        "## Access the ChromaDB collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9BrOwtpNeZW",
        "outputId": "42af7c73-e2b3-4747-92a0-bd22987bfbe0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': ['0'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [{'category': 'Journal Paper',\n",
              "   'document': '15 UAV Route Planning For Maximum Target Coverage.pdf'}],\n",
              " 'documents': ['Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 DOI : 10. 5121 / cseij. 2014. 410 3 27UAVROUTEPLANNING FORMAXIMUMTARGET COVERAGE MuratKarakaya1 1Department of Computer Engineering, Atilim University, Ankara, Turkey ABSTRACT Utilization of Unmanned Aerial Vehicles ( UAVs ) in military and civil operations is getting popular. One of the challenges in effectively tasking these expensive vehicles is planning'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chroma_collection.get(['0'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPT4PPcJrjU4"
      },
      "source": [
        "# LOAD MULTIPLE DOCUMENTS TO CHROMADB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VZp95gDm8wu"
      },
      "source": [
        "So far, we deal with only one file. Now, let's handle multiple files using the functions we have created so far.\n",
        "\n",
        "First, delete the above collection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hhtvJrLtY2E",
        "outputId": "39db55b5-4bb4-458b-bf6a-1cd1d042e5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection deleted successfully.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "  chroma_client.delete_collection(collection_name)\n",
        "  print(\"Collection deleted successfully.\")\n",
        "except Exception as e:\n",
        "  print(\"Error deleting collection:\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXXiRUNGH2eS"
      },
      "source": [
        "## Upload, Tokenize & Add Multiple Documents to A ChromaDB Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9GK86aOxQXp"
      },
      "outputs": [],
      "source": [
        "def load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model):\n",
        "\n",
        "  collection_name= collection_name\n",
        "  category= \"Journal Paper\"\n",
        "  sentence_transformer_model=sentence_transformer_model\n",
        "  embedding_function= embedding_functions.SentenceTransformerEmbeddingFunction(model_name=sentence_transformer_model)\n",
        "  chroma_client, chroma_collection = create_chroma_client(collection_name, embedding_function)\n",
        "  current_id = chroma_collection.count()\n",
        "  file_names = upload_multiple_files()\n",
        "  for file_name in file_names:\n",
        "    print(f\"Document: {file_name} is being processed to be added to the {chroma_collection.name} {chroma_collection.count()}\")\n",
        "    print(f\"current_id: {current_id} \")\n",
        "    pdf_texts = convert_PDF_Text(file_name)\n",
        "    text_chunksinChar = convert_Page_ChunkinChar(pdf_texts)\n",
        "    text_chunksinTokens = convert_Chunk_Token(text_chunksinChar,sentence_transformer_model)\n",
        "    ids,metadatas = add_meta_data(text_chunksinTokens,file_name,category, current_id)\n",
        "    current_id = current_id + len(text_chunksinTokens)\n",
        "    chroma_collection = add_document_to_collection(ids, metadatas, text_chunksinTokens, chroma_collection)\n",
        "    print(f\"Document: {file_name} added to the collection: {chroma_collection.count()}\")\n",
        "  return  chroma_client, chroma_collection\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KYuh7CmO3jQZ",
        "outputId": "664c7d59-7eeb-4a43-ded8-b0d70632e008"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f23b70b-1b17-4fa5-9c0b-b26481cb72b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f23b70b-1b17-4fa5-9c0b-b26481cb72b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving 15 UAV Route Planning For Maximum Target Coverage.pdf to 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "Saving 16 A Local Optimization Technique for Assigning New Targets ABSTRACT.pdf to 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf\n",
            "Saving 22 ISEAIA Risk Sensetive Routing Abstract.pdf to 22 ISEAIA Risk Sensetive Routing Abstract.pdf\n",
            "Saving 70 Biometric Verification.pdf to 70 Biometric Verification.pdf\n",
            "Document: 15 UAV Route Planning For Maximum Target Coverage (1).pdf is being processed to be added to the Papers 0\n",
            "current_id: 0 \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n",
            "ERROR:pypdf._cmap:Advanced encoding /SymbolSetEncoding not implemented yet\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document:  15 UAV Route Planning For Maximum Target Coverage (1).pdf  chunk size:  8\n",
            "\n",
            "Total number of chunks (document splited by max char = 1500):         14\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of chunks (document splited by 128 tokens per chunk):       41\n",
            "Before inserting, the size of the collection:  0\n",
            "After inserting, the size of the collection:  41\n",
            "Document: 15 UAV Route Planning For Maximum Target Coverage (1).pdf added to the collection: 41\n",
            "Document: 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf is being processed to be added to the Papers 41\n",
            "current_id: 41 \n",
            "Document:  16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf  chunk size:  1\n",
            "\n",
            "Total number of chunks (document splited by max char = 1500):         2\n",
            "\n",
            "Total number of chunks (document splited by 128 tokens per chunk):       6\n",
            "Before inserting, the size of the collection:  41\n",
            "After inserting, the size of the collection:  47\n",
            "Document: 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf added to the collection: 47\n",
            "Document: 22 ISEAIA Risk Sensetive Routing Abstract.pdf is being processed to be added to the Papers 47\n",
            "current_id: 47 \n",
            "Document:  22 ISEAIA Risk Sensetive Routing Abstract.pdf  chunk size:  1\n",
            "\n",
            "Total number of chunks (document splited by max char = 1500):         1\n",
            "\n",
            "Total number of chunks (document splited by 128 tokens per chunk):       2\n",
            "Before inserting, the size of the collection:  47\n",
            "After inserting, the size of the collection:  49\n",
            "Document: 22 ISEAIA Risk Sensetive Routing Abstract.pdf added to the collection: 49\n",
            "Document: 70 Biometric Verification.pdf is being processed to be added to the Papers 49\n",
            "current_id: 49 \n",
            "Document:  70 Biometric Verification.pdf  chunk size:  6\n",
            "\n",
            "Total number of chunks (document splited by max char = 1500):         19\n",
            "\n",
            "Total number of chunks (document splited by 128 tokens per chunk):       46\n",
            "Before inserting, the size of the collection:  49\n",
            "After inserting, the size of the collection:  95\n",
            "Document: 70 Biometric Verification.pdf added to the collection: 95\n"
          ]
        }
      ],
      "source": [
        "chroma_client, chroma_collection= load_multiple_pdfs_to_ChromaDB(collection_name,sentence_transformer_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12CqLuvB3ik9",
        "outputId": "80eb3935-422d-4532-9104-aa15a871113f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': ['84'],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [{'category': 'Journal Paper',\n",
              "   'document': '70 Biometric Verification.pdf'}],\n",
              " 'documents': ['minimum set of requirements Cancellation and revocation of the biometrics are enabled by the change of encryption key Access devices can be produced by commercial companies Supports commercial competition among access device producers Disadv antages Requires a decryption step in biometric verification process Biometric storage structure will be revealed Verification algorithm specifications should be published 5. 4. Alternative 3 Advantages Biometric storage structure is hidden Verification algorith m specifications is hidden Local biometric verification No need for a network connection No need for a central service Sensor specifications can be shared with'],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chroma_collection.get(['84'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZuYsYnpSD35J",
        "outputId": "358e9e16-876b-47d9-8ca8-c377922e3618"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [],\n",
              " 'embeddings': None,\n",
              " 'metadatas': [],\n",
              " 'documents': [],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['metadatas', 'documents']}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chroma_collection.get(['64'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWdk1sXPd99p"
      },
      "source": [
        "## Query & Retrieve Chunks from ChromaDB\n",
        "\n",
        "This function is designed to retrieve metadata associated with documents that are similar to a given **query** using a Chroma vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i37cx-Mv3eDp"
      },
      "outputs": [],
      "source": [
        "def retrieveDocs(chroma_collection, query, n_results=5, return_only_docs=False):\n",
        "    results = chroma_collection.query(query_texts=[query],\n",
        "                                      include= [ \"documents\",\"metadatas\",'distances' ],\n",
        "                                      n_results=n_results)\n",
        "\n",
        "    if return_only_docs:\n",
        "        return results['documents'][0]\n",
        "    else:\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "tyjm_hjyiove",
        "outputId": "d8f4e357-7043-42e9-ab07-d12ab3664ca3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nIn 16 A Local Optimization Technique for Assigning New Targets ABSTRACT:\\n\\nRoute planning can be static or dynamic. In static route planning, routes are\\nconstructed according to given UAVs and targets and do not change during\\nthe mission. However, in dynamic route planning, number of routes or UAVs\\ncan alter which requires the update of existing routes to adopt these changes.\\n\\n'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query = \"What are the main difference in active and passive path scheduling?\"\n",
        "\n",
        "'''\n",
        "In 16 A Local Optimization Technique for Assigning New Targets ABSTRACT:\n",
        "\n",
        "Route planning can be static or dynamic. In static route planning, routes are\n",
        "constructed according to given UAVs and targets and do not change during\n",
        "the mission. However, in dynamic route planning, number of routes or UAVs\n",
        "can alter which requires the update of existing routes to adopt these changes.\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAFFztpgOQDI"
      },
      "outputs": [],
      "source": [
        "results=retrieveDocs(chroma_collection, query, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPK4Lsw1rE6k",
        "outputId": "c1efbc63-c6d1-43e4-aef8-79c660ab819b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ids': [['42', '34', '18', '44', '21', '4', '15', '31', '43', '6']],\n",
              " 'distances': [[1.3230979442596436,\n",
              "   1.4107954502105713,\n",
              "   1.4304471015930176,\n",
              "   1.4979865550994873,\n",
              "   1.5068368911743164,\n",
              "   1.5119848251342773,\n",
              "   1.5183390378952026,\n",
              "   1.5194307565689087,\n",
              "   1.5206507444381714,\n",
              "   1.530265212059021]],\n",
              " 'metadatas': [[{'category': 'Journal Paper',\n",
              "    'document': '16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf'},\n",
              "   {'category': 'Journal Paper',\n",
              "    'document': '15 UAV Route Planning For Maximum Target Coverage (1).pdf'}]],\n",
              " 'embeddings': None,\n",
              " 'documents': [[', routes are constructed according to given UAVs and targets and do not change during the mission. However, in dynamic route planning, number of routes or UAVs can alter which requires the update of existing routes to adopt these changes. For example, some of the UAVs can be lost during the mission or new targets might pop up after the take - off. This article proposes an iterative local optimization for the distribution of new targets to the existing routes in dynamic route planning. In the proposed solution, it is supposed that all UAVs have the same flight ranges, their initial routes are planned, and',\n",
              "   'Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 34The prelimin ary results show the effectiveness of the MMAS in route planning. We would like to extend the work by defining different performance metrics and executing the experiments with different location set ups. REFERENCES [ 1 ] Bektas, T. ( 2006 ). The multiple trav eling salesman problem : an overview of formulations and solution procedures. Omega, 34 ( 3 ), 209 - 219. [ 2 ] Dorigo, M.',\n",
              "   'with less cost, that is covering more targets, leave more pheromone on the paths to provide positive feedback for the other ants. 4. 4. Calculating Heuristic Value The heuristic value ( ηij ) between two locations is defined as ijijd1 =, whereijdis the distance between the locations. 4. 5. Algorithm Using the steps defined above an implementation of the MMAS is given in Table 1. We input the target list ( H ), the distances between the targets ( dij ), the flight ra nge ( FR ), and the number of UAVs',\n",
              "   'follows. In the first phase of the algorithm, a n UAV with the highest slack range is picked and its route is modified by inserting a new target at a time. Adding a new target to an existing route causes an increase in the route distance, which is called update cost. If the update cost is not greater than the slack range, the new target is insert ed to the route. After finishing attempts with all new targets, if any of them is left over, insertion process is execute d with the UAV having the next highest slack range as described above until either all UAV',\n",
              "   'UAV _ used < UAV ) { next = find _ Next _ Target ( ) ; if ( base _ Reachable ( next ) ) { move ( next ) ; remaining _ Range - = dcurrent, next ; target _ Number + + ; } else { move ( base ) ; UAV _ used + + ; remaining _ Range = FR ; } } / / end _ while evoporate _ Pheromone ( ) ; update _ Pheromone ( ) ; update _ Best _ Solution ( ) ; } / / end _ for _ each _ ant } return ( Best _ Solution ) ;',\n",
              "   '] and the Vehicle Routing Problem ( VRP ) [ 6 ]. In these well - defined problems, it is mostly assume d that travelling salesmen or vehicles should visit all the targets and the target function is defined as to find a minimum - distant route. Even, in the constraint versions of the mTSP and VRP, some other restrictions ( visiting time windows, number of depot s, etc. ) are included ; it is still assumed that there exists enough number of travelling salesmen or vehicles to cover all the given locations. However, in reality the number and flight range of UAVs might be ins',\n",
              "   'Thus, if a routing plan can lead to visit all the targets, its cos t will be zero. The initial solution is constructed using Nearest Neighbors heuristic. The minimum pheromone value is defined as max10 min * ) 1 ( iteration p - = ( 6 ) As a result of Eq. ( 6 ), any edge would have pheromone at least ten times evaporat ed value of the maximum pheromone value. Thus, we do not allow unvisited edges get very low pheromone values which otherwise would decrease their probability. 4. 3. Updating Ph',\n",
              "   ', 4 UAVs are successfully routed by the MMAS to cover all the targets while the NN prepares a routing plan for the same number of UAVs missing 4 % of the targets. Table 5. The target coverage ratios for the heuristics when FR = CD * 2. UAV TCNN TCMMAS 1 11 % 12 % 3 20 % 29 % 5 30 % 35 % 7 34 % 38 % 9 36 % 40 % 11 38 % 41 % 13 40 % 41 % 14 41 % 41 % 1 11 % 12 % 3. CONCLUSIONS In this work, we define',\n",
              "   'they have already visited some of the targets accor ding to these routes. Furthermore, for each UAV, the slack range which is the difference between the flight range and initial route distance is calculated. Whenever some new targets appear, t he proposed iterative insertion algorithm executes as',\n",
              "   'Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 28In the proposed solution, each ant constructs routes for the given number of UAVs using pheromone and heuristic information. After each iteration, the solution which covers more targets with less route distance is selected as the iteration - best solution and the pheromone values of the edges on that route are increased. According to the termination condition, the algorithm stops and outputs the best route found so far as the result. To evaluate the success of the proposed method,']],\n",
              " 'uris': None,\n",
              " 'data': None,\n",
              " 'included': ['documents', 'metadatas', 'distances']}"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaLCI1m1rRHq"
      },
      "outputs": [],
      "source": [
        "retrieved_documents = results['documents'][0]\n",
        "if len(retrieved_documents) == 0:\n",
        "   print(\"No results found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uBE2kRMJQF4"
      },
      "source": [
        "## Show the retrieved chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7431h44iucn"
      },
      "outputs": [],
      "source": [
        "def show_results(results, return_only_docs=False):\n",
        "\n",
        "  if return_only_docs:\n",
        "    retrieved_documents = results\n",
        "    if len(retrieved_documents) == 0:\n",
        "      print(\"No results found.\")\n",
        "      return\n",
        "    for i, doc in enumerate(retrieved_documents):\n",
        "      print(f\"Document {i+1}:\")\n",
        "      print(\"\\tDocument Text: \")\n",
        "      display(to_markdown(doc));\n",
        "  else:\n",
        "\n",
        "      retrieved_documents = results['documents'][0]\n",
        "      if len(retrieved_documents) == 0:\n",
        "          print(\"No results found.\")\n",
        "          return\n",
        "      retrieved_documents_metadata = results['metadatas'][0]\n",
        "      retrieved_documents_distances = results['distances'][0]\n",
        "      print(\"------- retreived documents -------\\n\")\n",
        "\n",
        "      for i, doc in enumerate(retrieved_documents):\n",
        "          print(f\"Document {i+1}:\")\n",
        "          print(\"\\tDocument Text: \")\n",
        "          display(to_markdown(doc));\n",
        "          print(f\"\\tDocument Source: {retrieved_documents_metadata[i]['document']}\")\n",
        "          print(f\"\\tDocument Source Type: {retrieved_documents_metadata[i]['category']}\")\n",
        "          print(f\"\\tDocument Distance: {retrieved_documents_distances[i]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oiAS4JkTi1ZQ",
        "outputId": "b3c2b015-1769-46d4-e461-90b470ae9ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- retreived documents -------\n",
            "\n",
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> , routes are constructed according to given UAVs and targets and do not change during the mission. However, in dynamic route planning, number of routes or UAVs can alter which requires the update of existing routes to adopt these changes. For example, some of the UAVs can be lost during the mission or new targets might pop up after the take - off. This article proposes an iterative local optimization for the distribution of new targets to the existing routes in dynamic route planning. In the proposed solution, it is supposed that all UAVs have the same flight ranges, their initial routes are planned, and"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3230979442596436\n",
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 34The prelimin ary results show the effectiveness of the MMAS in route planning. We would like to extend the work by defining different performance metrics and executing the experiments with different location set ups. REFERENCES [ 1 ] Bektas, T. ( 2006 ). The multiple trav eling salesman problem : an overview of formulations and solution procedures. Omega, 34 ( 3 ), 209 - 219. [ 2 ] Dorigo, M."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4107954502105713\n",
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> with less cost, that is covering more targets, leave more pheromone on the paths to provide positive feedback for the other ants. 4. 4. Calculating Heuristic Value The heuristic value ( ηij ) between two locations is defined as ijijd1 =, whereijdis the distance between the locations. 4. 5. Algorithm Using the steps defined above an implementation of the MMAS is given in Table 1. We input the target list ( H ), the distances between the targets ( dij ), the flight ra nge ( FR ), and the number of UAVs"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4304471015930176\n",
            "Document 4:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> follows. In the first phase of the algorithm, a n UAV with the highest slack range is picked and its route is modified by inserting a new target at a time. Adding a new target to an existing route causes an increase in the route distance, which is called update cost. If the update cost is not greater than the slack range, the new target is insert ed to the route. After finishing attempts with all new targets, if any of them is left over, insertion process is execute d with the UAV having the next highest slack range as described above until either all UAV"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4979865550994873\n",
            "Document 5:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> UAV _ used < UAV ) { next = find _ Next _ Target ( ) ; if ( base _ Reachable ( next ) ) { move ( next ) ; remaining _ Range - = dcurrent, next ; target _ Number + + ; } else { move ( base ) ; UAV _ used + + ; remaining _ Range = FR ; } } / / end _ while evoporate _ Pheromone ( ) ; update _ Pheromone ( ) ; update _ Best _ Solution ( ) ; } / / end _ for _ each _ ant } return ( Best _ Solution ) ;"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5068368911743164\n",
            "Document 6:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> ] and the Vehicle Routing Problem ( VRP ) [ 6 ]. In these well - defined problems, it is mostly assume d that travelling salesmen or vehicles should visit all the targets and the target function is defined as to find a minimum - distant route. Even, in the constraint versions of the mTSP and VRP, some other restrictions ( visiting time windows, number of depot s, etc. ) are included ; it is still assumed that there exists enough number of travelling salesmen or vehicles to cover all the given locations. However, in reality the number and flight range of UAVs might be ins"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5119848251342773\n",
            "Document 7:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Thus, if a routing plan can lead to visit all the targets, its cos t will be zero. The initial solution is constructed using Nearest Neighbors heuristic. The minimum pheromone value is defined as max10 min * ) 1 ( iteration p - = ( 6 ) As a result of Eq. ( 6 ), any edge would have pheromone at least ten times evaporat ed value of the maximum pheromone value. Thus, we do not allow unvisited edges get very low pheromone values which otherwise would decrease their probability. 4. 3. Updating Ph"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5183390378952026\n",
            "Document 8:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> , 4 UAVs are successfully routed by the MMAS to cover all the targets while the NN prepares a routing plan for the same number of UAVs missing 4 % of the targets. Table 5. The target coverage ratios for the heuristics when FR = CD * 2. UAV TCNN TCMMAS 1 11 % 12 % 3 20 % 29 % 5 30 % 35 % 7 34 % 38 % 9 36 % 40 % 11 38 % 41 % 13 40 % 41 % 14 41 % 41 % 1 11 % 12 % 3. CONCLUSIONS In this work, we define"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5194307565689087\n",
            "Document 9:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> they have already visited some of the targets accor ding to these routes. Furthermore, for each UAV, the slack range which is the difference between the flight range and initial route distance is calculated. Whenever some new targets appear, t he proposed iterative insertion algorithm executes as"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 16 A Local Optimization Technique for Assigning New Targets ABSTRACT (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5206507444381714\n",
            "Document 10:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 28In the proposed solution, each ant constructs routes for the given number of UAVs using pheromone and heuristic information. After each iteration, the solution which covers more targets with less route distance is selected as the iteration - best solution and the pheromone values of the edges on that route are increased. According to the termination condition, the algorithm stops and outputs the best route found so far as the result. To evaluate the success of the proposed method,"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.530265212059021\n"
          ]
        }
      ],
      "source": [
        "show_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgLIpCglw77e"
      },
      "source": [
        "NOTE: Sometimes **totally unrelated** chunks can be fetched:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "IgMYTqoIHzNa",
        "outputId": "f1640af5-9699-476f-a47f-c0efdb9581c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- retreived documents -------\n",
            "\n",
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Verification System."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 70 Biometric Verification.pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4642446041107178\n",
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> or digital - certificate to any one he chooses from a theoretically infi nite alternative pool. But for the biometrics, options are limited especially for hand and retina vein maps. 3. Problems w ith The Current Design Turkish national e - ID card access devices should meet a set of security requirements, such as blocking the remot e access, keeping specific event / user logs and being temper resistant etc. In order to certify whether the devices meet these requirements, they are obliged to Common Criteria ( CC ) tests with a predefined protection profile [ 11 ]"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 70 Biometric Verification.pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.464350938796997\n",
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Following the technological feasibility, functionality, pilot usage and security studies, actual production and dissemination of e - ID cards were commenced. Pu blished standards are one of several outcomes of these studies as well. So that, the definitions, methods and specifications in standards were assumed to be well studied and tested. Apparently, e - ID cards are instruments with high privacy and security requ irements. The content of the card is strongly private and sensible to exploitation. It goes without saying, security and privacy considerations should take precedence in e - ID card specifications. In line"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 70 Biometric Verification.pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4691274166107178\n",
            "Document 4:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> should be known by the designer. Since, with the purpose of verifying the identity, the device is supposed to compare the scanned biometrics with the biometric data which is read from e - ID card, assuming proper access rights such as PIN and / or certificates are provided. Nevertheless, the data structure and the fea ture notation used in e - ID card for biometrics is not published. This means, e - ID card access device producers will not be able to develop a verification system running on the device. On the other hand, if the producer opts for verification on"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 70 Biometric Verification.pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.4903249740600586\n",
            "Document 5:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> device producers, so that access devices can verify the scanned biometrics. But a central validity check is introduced to the process steps with a minimum network and communication overhead. For central verifica tion a hash of the biometric data on e - ID card is to be transmitted to a government controlled validation server and validity result is received. This mode of operation enables the cancellation and revocation of biometrics. 5. Comparison of t he Alternative s As we have mention ed in the previous section each biometric verification algorithm has its own advantages and disa"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 70 Biometric Verification.pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.5029150247573853\n"
          ]
        }
      ],
      "source": [
        "query = \"What is the controllable text generation?\"\n",
        "results=retrieveDocs(chroma_collection, query)\n",
        "show_results(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "id": "7N_CwJhZj3kh",
        "outputId": "8e85c0bc-121a-4021-d63d-c09214420866"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> sol ution based on the NN heuristic. KEYWORDS Unmanned Aerial Vehicles ( UAVs ), r outing, target coverage, Max - Min Ant Colony Optimization 1. INTRODUCTION This document describes, and is written to conform to, author guidelines for the journals of AIRCCseries. It is prepared in Microsoft Word as a. doc document. Although other mea ns of preparation are acceptable, final, camera - ready versions must conform to this layout. Microsoft"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Word terminology is used where appropriate in this document. Although formatting instructions may often appear daunting, the simplest approach is to use this template and insert headings and text into it as appropriate. The importance and the impact of using Unmanned Aerial Vehicles ( UAVs ) in military and civil operations are increasing [ 3, 4, 5 ]. One of the issues faced for efficient usage of UAVs is plann ing the flight routes to monitor all or the maximum number of the given targets. This problem is related with the Multiple Travelling Salesman Problem ( mTSP ) [ 1"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> ( UAV ) to the algorithm. The algorithm first calculates an initial solution by applying the NN heuristic. By using the cost of the initial solution, minimum and maximum pheromone values are set. Then, using the distance matr ix, the heuristic values are calculated. After creating a number of ants ( m ), each ant builds its solution and updates the pheromone values according to the cost of the solution. When, a pre - defined number of iterations has been executed algorithm terminates by outputting the best solution found so far."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 4:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> Computer Science & Engineering : An International Journal ( CSEIJ ), Vol. 4, No. 1, February 2014 32Table 2. Simulation Parameters and default values. Parameter Definition Default Value DF Data File CH150. dat T Total Number of Targets 149 dij Distance matrix Calculated according to the input file. FR Flight range 3 p Pheromone evapo ration 0. 01 Heuristic effect factor 7 m Number of ants 151 t Iteration number 1000 To determine the flight range ( FR ) we define a parameter called Critical Distance ( CD ). TheCD is the"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 5:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> } 3. SIMULATION MODELANDRESULTS We have implemented the proposed MMAS solution using the MASON simulation lib rary ( Luke et al. 2003 ). The simulation and MMAS parameters with the default values are given in Table 2. We use several different TSP data files ( TSPLIB, 1995 ) with various flight range and UAV number to observe the results. Below we report only the preli minary results for the TSP data file name CH150. The first location in the data file is selected as the base where all the UAVs are assumed to"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results=retrieveDocs(chroma_collection, query, return_only_docs= True)\n",
        "show_results(results,  return_only_docs=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ReoLvjnBNOJD"
      },
      "source": [
        "# Filtering Results According to Metadata\n",
        "Let's explore ChromaDB's filtering capabilities. We might want to filter results based on specific metadata fields associated with the documents (e.g., author, date, category)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "ggMsmKnCNBg-",
        "outputId": "857de693-3cb5-4509-a9fa-8bebf473ea98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- retreived documents -------\n",
            "\n",
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> distance of the farthest target from the selected base. We test threeFRs with respect to the CDas Case 1 : FR = CD, Case 2 : FR = CD / 2, and Case 3 : FR = CD * 2. The main performance metric, Target Coverage ( TC ), is the ratio of the number of the targets visited by all the UAVs to the existing targets as formulated below : 100 * allvisited TTTC = ( 9 ) To obtain the results, we run each simulation 10 times and get the averages of these results to find the mean values. 5. 1. Results"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3038585186004639\n",
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> , 4 UAVs are successfully routed by the MMAS to cover all the targets while the NN prepares a routing plan for the same number of UAVs missing 4 % of the targets. Table 5. The target coverage ratios for the heuristics when FR = CD * 2. UAV TCNN TCMMAS 1 11 % 12 % 3 20 % 29 % 5 30 % 35 % 7 34 % 38 % 9 36 % 40 % 11 38 % 41 % 13 40 % 41 % 14 41 % 41 % 1 11 % 12 % 3. CONCLUSIONS In this work, we define"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.31107759475708\n",
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> on the maximum and minimum values of the pheromone values that can be compiled on an edge. We apply MMAS to find a route planning to cover most of the targets as explained belo w. 4. APPLYINGMMASTOTARGETCOVERAGE PROBLEM Below, we first explain the MMAS basics and then provide the algorithm to generate a solution to cover maximum number of targets. 2. 1. Selecting Next Target In MMAS, each artificial ant tries to create a route planning for all the UAVs by visiting targets considering the given problem constraints. Beginning"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3237237930297852\n",
            "Document 4:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> generate more target coverage compared to the NN heuristic."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3665157556533813\n",
            "Document 5:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> ] and the Vehicle Routing Problem ( VRP ) [ 6 ]. In these well - defined problems, it is mostly assume d that travelling salesmen or vehicles should visit all the targets and the target function is defined as to find a minimum - distant route. Even, in the constraint versions of the mTSP and VRP, some other restrictions ( visiting time windows, number of depot s, etc. ) are included ; it is still assumed that there exists enough number of travelling salesmen or vehicles to cover all the given locations. However, in reality the number and flight range of UAVs might be ins"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3945647478103638\n"
          ]
        }
      ],
      "source": [
        "# Define your query and desired document\n",
        "query = \"What is Target Coverage?\"\n",
        "document_filter = \"15 UAV Route Planning For Maximum Target Coverage (1).pdf\"\n",
        "\n",
        "results = chroma_collection.query(\n",
        "    query_texts=[query],\n",
        "    include=[\"documents\", \"metadatas\", \"distances\"],\n",
        "    where={\"document\": document_filter},\n",
        "    n_results=5)\n",
        "\n",
        "show_results(results)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UROBBMsJtDpI"
      },
      "source": [
        "Let's modify the **retrieveDocs()** function so that it can handle filters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cNCzyJUqQqx"
      },
      "outputs": [],
      "source": [
        "def retrieveDocs(chroma_collection, query, n_results=5,\n",
        "                 return_only_docs=False, filterType=None, filterValue=None):\n",
        "    if filterType is not None and filterValue is not None:\n",
        "        results = chroma_collection.query(\n",
        "            query_texts=[query],\n",
        "            include=[\"documents\", \"metadatas\", \"distances\"],\n",
        "            where={filterType: filterValue},\n",
        "            n_results=n_results)\n",
        "\n",
        "    else:\n",
        "        results = chroma_collection.query(\n",
        "            query_texts=[query],\n",
        "            include= [ \"documents\",\"metadatas\",'distances' ],\n",
        "            n_results=n_results)\n",
        "\n",
        "    if return_only_docs:\n",
        "        return results['documents'][0]\n",
        "    else:\n",
        "        return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZuVw_qQuCD0"
      },
      "source": [
        "Let's test the revised function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "17XME4gOuAjH",
        "outputId": "4db611bc-cc16-4594-fb1e-f961dde54e90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- retreived documents -------\n",
            "\n",
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> distance of the farthest target from the selected base. We test threeFRs with respect to the CDas Case 1 : FR = CD, Case 2 : FR = CD / 2, and Case 3 : FR = CD * 2. The main performance metric, Target Coverage ( TC ), is the ratio of the number of the targets visited by all the UAVs to the existing targets as formulated below : 100 * allvisited TTTC = ( 9 ) To obtain the results, we run each simulation 10 times and get the averages of these results to find the mean values. 5. 1. Results"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3038585186004639\n",
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> , 4 UAVs are successfully routed by the MMAS to cover all the targets while the NN prepares a routing plan for the same number of UAVs missing 4 % of the targets. Table 5. The target coverage ratios for the heuristics when FR = CD * 2. UAV TCNN TCMMAS 1 11 % 12 % 3 20 % 29 % 5 30 % 35 % 7 34 % 38 % 9 36 % 40 % 11 38 % 41 % 13 40 % 41 % 14 41 % 41 % 1 11 % 12 % 3. CONCLUSIONS In this work, we define"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.31107759475708\n",
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> on the maximum and minimum values of the pheromone values that can be compiled on an edge. We apply MMAS to find a route planning to cover most of the targets as explained belo w. 4. APPLYINGMMASTOTARGETCOVERAGE PROBLEM Below, we first explain the MMAS basics and then provide the algorithm to generate a solution to cover maximum number of targets. 2. 1. Selecting Next Target In MMAS, each artificial ant tries to create a route planning for all the UAVs by visiting targets considering the given problem constraints. Beginning"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3237237930297852\n",
            "Document 4:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> generate more target coverage compared to the NN heuristic."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3665157556533813\n",
            "Document 5:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> ] and the Vehicle Routing Problem ( VRP ) [ 6 ]. In these well - defined problems, it is mostly assume d that travelling salesmen or vehicles should visit all the targets and the target function is defined as to find a minimum - distant route. Even, in the constraint versions of the mTSP and VRP, some other restrictions ( visiting time windows, number of depot s, etc. ) are included ; it is still assumed that there exists enough number of travelling salesmen or vehicles to cover all the given locations. However, in reality the number and flight range of UAVs might be ins"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3945647478103638\n"
          ]
        }
      ],
      "source": [
        "# Define your query and desired document\n",
        "query = \"What is Target Coverage?\"\n",
        "filterType = \"document\"\n",
        "filterValue = \"15 UAV Route Planning For Maximum Target Coverage (1).pdf\"\n",
        "\n",
        "results = retrieveDocs(chroma_collection,query,\n",
        "                       filterType=filterType,\n",
        "                       filterValue=filterValue,\n",
        "                       n_results=5 )\n",
        "show_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC1NMkHLvFcY"
      },
      "source": [
        "NOTE: Sometimes **nothing** can be fetched or **unrelated** chunks can be retrieved because of **filters**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MqvRJe_vDpH",
        "outputId": "95d96165-9058-476a-b79e-49ae7e2e487e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No results found.\n"
          ]
        }
      ],
      "source": [
        "# Define your query and desired document\n",
        "query = \"Explain Ant Colony Optimization in UAV route planning?\"\n",
        "filterType = \"document\"\n",
        "filterValue = \"70 Biometric Verification (1).pdf\"\n",
        "\n",
        "results = retrieveDocs(chroma_collection,query,\n",
        "                       filterType=filterType,\n",
        "                       filterValue=filterValue,\n",
        "                       n_results=5 )\n",
        "show_results(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITtISSZGyc-V"
      },
      "source": [
        "# Remove Less Related / Similar / Close Chunks\n",
        "\n",
        "To eliminate unrelated chunks using **document distance** values in ChromaDB, we can filter the results based on a **distance threshold**. The distance value indicates how similar the document is to the query, with smaller values representing higher similarity (depending on the distance metric used). Here's a function to implement such filtering:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iv9ExcHH5SLY"
      },
      "outputs": [],
      "source": [
        "def remove_less_related_chunks(results, distance_threshold):\n",
        "    filtered_results = {\n",
        "        \"ids\": [[]],\n",
        "        \"distances\": [[]],\n",
        "        \"metadatas\": [[]],\n",
        "        \"documents\": [[]]\n",
        "    }\n",
        "\n",
        "    for i in range(len(results[\"distances\"][0])):\n",
        "        if results[\"distances\"][0][i] <= distance_threshold:\n",
        "            filtered_results[\"ids\"][0].append(results[\"ids\"][0][i])\n",
        "            filtered_results[\"distances\"][0].append(results[\"distances\"][0][i])\n",
        "            filtered_results[\"metadatas\"][0].append(results[\"metadatas\"][0][i])\n",
        "            filtered_results[\"documents\"][0].append(results[\"documents\"][0][i])\n",
        "\n",
        "    return filtered_results\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "Va6FfWRD5wQL",
        "outputId": "cf940531-eb36-4b83-d051-07b5725e7cc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "------- retreived documents -------\n",
            "\n",
            "Document 1:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> distance of the farthest target from the selected base. We test threeFRs with respect to the CDas Case 1 : FR = CD, Case 2 : FR = CD / 2, and Case 3 : FR = CD * 2. The main performance metric, Target Coverage ( TC ), is the ratio of the number of the targets visited by all the UAVs to the existing targets as formulated below : 100 * allvisited TTTC = ( 9 ) To obtain the results, we run each simulation 10 times and get the averages of these results to find the mean values. 5. 1. Results"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3038585186004639\n",
            "Document 2:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> , 4 UAVs are successfully routed by the MMAS to cover all the targets while the NN prepares a routing plan for the same number of UAVs missing 4 % of the targets. Table 5. The target coverage ratios for the heuristics when FR = CD * 2. UAV TCNN TCMMAS 1 11 % 12 % 3 20 % 29 % 5 30 % 35 % 7 34 % 38 % 9 36 % 40 % 11 38 % 41 % 13 40 % 41 % 14 41 % 41 % 1 11 % 12 % 3. CONCLUSIONS In this work, we define"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.31107759475708\n",
            "Document 3:\n",
            "\tDocument Text: \n"
          ]
        },
        {
          "data": {
            "text/markdown": [
              "> on the maximum and minimum values of the pheromone values that can be compiled on an edge. We apply MMAS to find a route planning to cover most of the targets as explained belo w. 4. APPLYINGMMASTOTARGETCOVERAGE PROBLEM Below, we first explain the MMAS basics and then provide the algorithm to generate a solution to cover maximum number of targets. 2. 1. Selecting Next Target In MMAS, each artificial ant tries to create a route planning for all the UAVs by visiting targets considering the given problem constraints. Beginning"
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tDocument Source: 15 UAV Route Planning For Maximum Target Coverage (1).pdf\n",
            "\tDocument Source Type: Journal Paper\n",
            "\tDocument Distance: 1.3237237930297852\n"
          ]
        }
      ],
      "source": [
        "distance_threshold = 1.36\n",
        "closer_results = remove_less_related_chunks(results, distance_threshold)\n",
        "show_results(closer_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogclfcctFtRJ"
      },
      "source": [
        "# SUMMARY\n",
        "\n",
        "In this exciting tutorial series, we are developing a Retrieval Augmented Generation (RAG) application. If you missed the first part where we covered how to code the GEMINI API for text generation and chat, be sure to check that out.\n",
        "\n",
        "In this second part, we coded with ChromaDB for vector storage and similarity search with multiple documents.\n",
        "\n",
        "In this tutorial, we learned:\n",
        "* How Does RAG Work? – Understand the fundamentals of Retrieval Augmented Generation.\n",
        "* Upload Single and Multiple PDF Documents to ChromaDB – Learn to handle various document types.\n",
        "* Convert PDF Content to Text Format – * Extract text from PDFs efficiently.\n",
        "* Convert Text from Pages to Chunks – Organize text for better processing.\n",
        "* Tokenize the Text – Prepare your text data for machine learning.\n",
        "* Use the Sentence Transformers Library – Implement advanced text encoding techniques.\n",
        "* Understand Vector Embedding – Grasp the concept of embedding vectors.\n",
        "* Create a ChromaDB Instance for Single and Multiple Files/Documents – Set up your database for efficient storage.\n",
        "* Query and Retrieve Chunks from ChromaDB – Learn to search and retrieve relevant information.\n",
        "* Filtering Results – Refine your search results.\n",
        "* Remove Less Related/Less Similar Chunks – Improve the accuracy of your retrieval process.\n",
        "\n",
        "All the above steps was implemented and coded in Python on Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBCYaVPzFPAb"
      },
      "source": [
        "."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMhNr2SSYA2r1IFRGJ2DdVx",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
